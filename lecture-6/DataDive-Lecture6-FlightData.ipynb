{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dive Week 6: Logistic Regression \n",
    "\n",
    "This week we take a look at *logistic regression*, the first classification model we'll be covering in class. We'll be using `scikit-learn` in today's exercise. \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "As we discussed last week, logisitic regression is a *classification model* - meaning that it is designed to idenfity the likelihood that a given observed data point belongs to set class, or category. Today we'll be looking at a real world application of logistic regression using July 2019 flight data from the U.S. Department of Transportation's [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236). \n",
    "***\n",
    "\n",
    "![flights](https://media.giphy.com/media/Btn42lfKKrOzS/source.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://grantmlong.com/data/Flights-July2019.csv')\n",
    "print(df.shape)\n",
    "print(list(df))\n",
    "df.sample(5).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying a Target\n",
    "\n",
    "If you're a traveler, which variable might make the most to predict? How about if you are a travel booking site?\n",
    "\n",
    "Create and/or summarize the variable that you think makes the most sense to model. What percentage of flights fall into this category?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring our target has valid values\n",
    "\n",
    "We need to ensure that all of our target observations have valid values in order to ensure our model will run properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'XXX'\n",
    "df = df.loc[df[target].notna()] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Our Data\n",
    "\n",
    "As we start to put together a model, we'll want to think about the features that might make sense to use in our model. Ideally, these should be:\n",
    " 1. Available in advance.\n",
    " 2. Sensibly related to our target.\n",
    " 3. Capable of being encoded into a model. \n",
    " \n",
    "Let's summarize some potential features, and look at the ways in which they correlate with our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data\n",
    "\n",
    "To examine how well some potential categorical variables might work, we can summarize our target by each of the categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_feature = 'XXX'\n",
    "\n",
    "if df[potential_feature].nunique()<=20:\n",
    "\n",
    "    print(\n",
    "        df[[potential_feature, target]]\n",
    "        .groupby(potential_feature)\n",
    "        .agg(['mean', 'count'])\n",
    "        .sort_values(by=(target, 'mean'), ascending=False)\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\n",
    "        df[[potential_feature, target]]\n",
    "        .groupby(potential_feature)\n",
    "        .agg(['mean', 'count'])\n",
    "        .sort_values(by=(target, 'mean'), ascending=False).head(10)\n",
    "    )\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\n",
    "        df[[potential_feature, target]]\n",
    "        .groupby(potential_feature)\n",
    "        .agg(['mean', 'count'])\n",
    "        .sort_values(by=(target, 'mean'), ascending=False).tail(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables \n",
    "\n",
    "For continuous features, evaluating their predictive potential is slightly more straightforward. We can look at the distribution of the potential features by each class to gauge their relationship to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_feature = 'XXX'\n",
    "\n",
    "df.loc[(df[target]==0), potential_feature].hist(bins=20, alpha=.5, density=True, color='blue')\n",
    "df.loc[(df[target]==1), potential_feature].hist(bins=20, alpha=.5, density=True, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Feature Sets\n",
    "\n",
    "For each of the categorical features we'd like to include, we'll have to break each category - or a combination of categories - into a series of binary features. For continuous features, we'll have to ensure each row we'd like to include has a valid value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################        \n",
    "# Categorical features\n",
    "\n",
    "all_features = []\n",
    "categorical_features = ['XXX', 'XXX']\n",
    "top = 10\n",
    "\n",
    "for each_feature in categorical_features:\n",
    "    for f in df[each_feature].value_counts().index[:top].to_list():\n",
    "        df[each_feature+'='+f] = (df[each_feature]==f)*1\n",
    "        all_features.append(each_feature+'='+f)\n",
    "\n",
    "        \n",
    "####################################################################        \n",
    "# Continuous features\n",
    "\n",
    "continuous_features = ['XXX', 'XXX']\n",
    "\n",
    "for each_feature in continuous_features:\n",
    "    all_features.append(each_feature)\n",
    "\n",
    "        \n",
    "####################################################################        \n",
    "# Adding a constant\n",
    "df['constant'] = 1\n",
    "all_features.append('constant')\n",
    "    \n",
    "    \n",
    "df[all_features].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Model in `statsmodels`\n",
    "\n",
    "As we saw last week, `statsmodels` can be helpful if we want to visualize the summary statistics of our output. Just like linear regression, it only takes a few lines of code to use `statsmodels` to fit the model and print the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(df[target], df[all_features])\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Model in `sklearn`\n",
    "\n",
    "As we saw the past two weeks, `statsmodels` can be helpful if we want to visualize the summary statistics of our output. Documentation for the `LogisticRegression` object can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[all_features].values\n",
    "y = df[target].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's fit and score the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=20191016, solver='lbfgs').fit(X, y)\n",
    "print('The accuracy of our model is %0.1f%%' % (clf.score(X, y)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see where we went right and where we went wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['likelihood'] = clf.predict_proba(X)[:,1]\n",
    "\n",
    "df['likelihood'].hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top values where we failed to predict a bad flight: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_cols = ['FL_DATE', 'OP_CARRIER', 'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'likelihood', target]\n",
    "\n",
    "(\n",
    "    df.loc[(df[target]==1), interesting_cols]\n",
    "    .sort_values(by='likelihood', ascending=True)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at where we predicted a bad flight, but the flights were not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.loc[(df[target]==0), interesting_cols]\n",
    "    .sort_values(by='likelihood', ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a closer look at our summary metrics. How do they change as we change our cutoff value for our prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, threshold):\n",
    "    \n",
    "    df['predicted'] = (clf.predict_proba(X)[:,1]>=threshold)*1\n",
    "    accuracy = sum(df['predicted']==y)/len(y)\n",
    "    precision = df.loc[df.predicted==1, target].mean()\n",
    "    recall = df.loc[df[target]==1, 'predicted'].mean()\n",
    "    \n",
    "    return accuracy, precision, recall, sum(df['predicted'])\n",
    "\n",
    "for p in [.1, .2, .3, .4, .5, .6]:\n",
    "    print(p, calculate_metrics(df.copy(), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
